{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model](./sketch_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghinsa/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.layers as tf_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[unet](https://www.youtube.com/watch?v=81AvQQnpG4Q):explains the concatenation in the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(images,normalizer_fn=tf_layers.batch_norm,activation=tf.nn.leaky_relu):\n",
    "    \"\"\"\n",
    "    images:n*h*x*c\n",
    "    \"\"\"\n",
    "    \n",
    "    e1=tf_layers.conv2d(images,num_outputs=64,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    e2=tf_layers.conv2d(images,num_outputs=128,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    e3=tf_layers.conv2d(images,num_outputs=256,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    e4=tf_layers.conv2d(images,num_outputs=512,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    e5=tf_layers.conv2d(images,num_outputs=512,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    e6=tf_layers.conv2d(images,num_outputs=512,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    encoded=tf_layers.conv2d(images,num_outputs=512,kernel_size=4,stride=2,normalizer_fn=normalizer_fn,activation_fn=tf.nn.leaky_relu)\n",
    "    \n",
    "    num_images=images.get_shape()[0].value\n",
    "    #features=tf.reshape(encoded,[num_images,-1])\n",
    "    \n",
    "    return encoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images=tf.placeholder(\"float\",[None,256,256,nc])\n",
    "# init=tf.global_variables_initializer()\n",
    "# enc=encoder(images)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     u=sess.run(enc,feed_dict={images:img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x,n_channels,kernel=4,stride=2,activation_fn=tf.nn.leaky_relu,normalizer_fn=tf_layers.batch_norm):\n",
    "    \"\"\"\n",
    "    x is encoded\n",
    "    \"\"\"\n",
    "    h_new=(x.get_shape()[1].value)*stride\n",
    "    w_new=(x.get_shape()[2].value)*stride\n",
    "    up=tf.image.resize_nearest_neighbor(x,[h_new,w_new])\n",
    "    \n",
    "    return tf_layers.conv2d(up,num_outputs=n_channels,kernel_size=kernel,stride=1,normalizer_fn=normalizer_fn,activation_fn=activation_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(encoded,out_channels):\n",
    "    d6=tf_layers.droput(upsample(encoded,512))\n",
    "    d5=tf_layers.droput(upsample(tf.concat([d6,e6],3),512))\n",
    "    d4=upsample(tf.concat([d5,e5],3),512)\n",
    "    d3=upsample(tf.concat([d4,e4],3),256)\n",
    "    d2=upsample(tf.concat([d3,e3],3),128)\n",
    "    d1=upsample(tf.concat([d2,e2],3),64)\n",
    "    decoded=upsample(tf.concat([d1,e1],3),out_channels)\n",
    "    \n",
    "    return decoded\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uNet(images,out_channels=5):\n",
    "    encoded,features=encoder(images)\n",
    "    decoded=decode(encoded)\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsv=cv2.imread('1.png',0)\n",
    "imgtv=cv2.imread('2.png',0)\n",
    "img=np.dstack((imgsv,imgtv))\n",
    "nc=2\n",
    "img=np.reshape(img,(-1,256,256,nc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5-channel  image includes   \n",
    "1 a depth map  \n",
    "3 normal map  \n",
    "5 foreground mask(threshold 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses  \n",
    "Depth loss= $\\sum_{p}(d_{p} - d)f$ | f is 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_loss(pred,truth,mask):\n",
    "    \"\"\"\n",
    "    pred=nxhxwx1\n",
    "    truth=\"\n",
    "    mask=\"\n",
    "    \n",
    "    return normalized loss scalar\n",
    "    \"\"\"\n",
    "    loss=tf.subtract(pred-truth)\n",
    "    loss=tf.abs(loss)\n",
    "    loss=tf.boolean_mask(loss,tf.squeeze(mask,[3]))\n",
    "    nloss=tf.reduce_mean(loss)\n",
    "    nloss=nloss*pred.get_shape()[0].value\n",
    "    \n",
    "    return nloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(pred,truth,mask):\n",
    "    \"\"\"\n",
    "    pred=nxhxwx1\n",
    "    truth=\"\n",
    "    mask=\"\n",
    "    \n",
    "    return normalized loss scalar\n",
    "    \"\"\"\n",
    "    loss=depth_loss(pred,truth,mask)\n",
    "    nloss=loss*pred.get_shape()[3]\n",
    "    return nloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_loss(pred,truth):\n",
    "    #[-1,1] -> [0,1]\n",
    "    pred=pred*0.5+0.5\n",
    "    truth=truth*0.5+0.5\n",
    "    \n",
    "    loss=tf.multiply(truth,tf.log(tf.maximum(1e-6,pred)))\n",
    "    loss=loss+tf.multiply((1-truth),tf.log(tf.maximum(1e-6,1-pred)))\n",
    "    loss=tf.reduce_sum(-loss)\n",
    "    nloss=loss/np.prod(truth.get_shape().as_list[1:])\n",
    "    return nloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(pred,truth):\n",
    "    \"\"\"\n",
    "    pred=nxhxwxc\n",
    "    \"\"\"\n",
    "    depth_pred=pred[:,:,:,0]\n",
    "    depth_truth=truth[:,:,:,0]\n",
    "    normal_pred=pred[:,:,:,1:4]\n",
    "    normal_truth=truth[:,:,:,1:4]\n",
    "    mask_pred=pred[:,:,:,4]\n",
    "    mask_truth=truth[:,:,:,4]\n",
    "    \n",
    "    dl=depth_loss(depth_pred,depth_truth,mask_truth)\n",
    "    nl=normal_loss(normal_pred,normal_truth,mask_truth)\n",
    "    ml=mask_loss(mask_pred,mask_truth)\n",
    "    \n",
    "    return (dl+ml+nl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
